"""Copyright 2022 Google LLC

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    https://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('mainland.n.01')\n",
      "definition the main land mass of a country or continent; as distinguished from an island or peninsula\n",
      "examples []\n",
      "mainland.n.01 ['mainland']\n",
      "dict_keys(['mainland.n.01'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_synonyms(word, pretty_print=False):\n",
    "    synsets = wn.synsets(word)\n",
    "    synset_dict = {}\n",
    "    for synset in synsets:\n",
    "        print(synset)\n",
    "        print('definition', synset.definition())\n",
    "        print('examples', synset.examples())\n",
    "        lemmas = [l.name() for l in synset.lemmas() if '_' not in l.name()]\n",
    "        synset_dict[synset.name()] = lemmas\n",
    "    if pretty_print:\n",
    "        for name in synset_dict:\n",
    "            print(name, synset_dict[name])\n",
    "    return synset_dict\n",
    "\n",
    "#synset_dict = get_synonyms('cat', False)\n",
    "synset_dict = get_synonyms('mainland', True)\n",
    "print(synset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: Generate a list of all sentences\n",
    "# STEP 1: I just need to generate sentences\n",
    "# Specifically, I want to generate definition sentences and example sentences.\n",
    "# STEP 2: Update the script to take these sentences directly\n",
    "# STEP 3: Update the script to write the embeddings out to a different directory / filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def write_tsv(output_file, sentences, synset_name):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            f.write('\\t'.join([str(i), '1', synset_name, sentence, '\\n']))\n",
    "    return output_file\n",
    "\n",
    "synset_dict = {}\n",
    "\n",
    "output_dir = '/tmp/wordnet/'\n",
    "\n",
    "word_dir = '/usr/local/google/home/agoldie/data/gigaword/words/'\n",
    "words = [file.strip('.txt') for file in os.listdir(word_dir)]\n",
    "\n",
    "for word in words:\n",
    "    synsets = wn.synsets(word)\n",
    "    for synset in synsets:\n",
    "        name = synset.name()\n",
    "        if '/' in name:\n",
    "            continue\n",
    "        lemmas = [l.name() for l in synset.lemmas() if '_' not in l.name()]\n",
    "        if name not in synset_dict:\n",
    "            pos = synset.pos()\n",
    "            synset_dict[name] = True\n",
    "            # First, write out definition sentences.\n",
    "            definition = synset.definition().lower()\n",
    "            if pos == 'n':\n",
    "                definition_sentence = word + ' is ' + definition\n",
    "            elif pos == 'v':\n",
    "                definition_sentence = word + ' is to ' + definition\n",
    "            elif pos == 's' or pos == 'a' or pos == 'r':\n",
    "                definition_sentence = word + ' means ' + definition\n",
    "            else:\n",
    "                definition_sentence = definition\n",
    "            definition_file = os.path.join(output_dir, name + '_definition.tsv')\n",
    "            write_tsv(definition_file, [definition_sentence], name)\n",
    "            # Then, write out examples, if any.\n",
    "            examples = synset.examples()\n",
    "            examples = [e.lower() for e in examples]\n",
    "            if examples:\n",
    "                example_file = os.path.join(output_dir, name + '_examples.tsv')\n",
    "                write_tsv(example_file, examples, name)\n",
    "\n",
    "# for key in synset_dict:\n",
    "#     if len(synset_dict[key]) > 1:\n",
    "#         print(key, synset_dict[key])\n",
    "# synset_file = '/tmp/synset_dict.pckl'\n",
    "# with open(synset_file, 'wb') as f:\n",
    "#     pickle.dump(synset_dict, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synset_file = '/tmp/synset_dict.pckl'\n",
    "# with open(synset_file, 'rb') as g:   \n",
    "#     synset_dict = pickle.load(g) \n",
    "# print(synset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52687\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /tmp/wordnet/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember how to pickle?\n",
    "# Maybe just save the words and lemmas in the dictionary and write out the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "101 23016 2003 2000 4894 2004 2065 2011 23016 102"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
